# -*- coding: utf-8 -*-
"""Leitura de textos dentro de imagens.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1I-jAMUlrSdO2uDw_tuaZ9OGXYjPseqds
"""

!pip install -q easyocr

!pip install opencv-python

"""# For documents that are images"""

import cv2
import easyocr

image = cv2.imread('/content/artigo.jpg') #put your digital document image here
reader = easyocr.Reader(lang_list=['pt'], gpu=True)

text = reader.readtext(image=image, detail=0, paragraph=True)
text

"""Just take care with the zeros and O, because sometimes the model can misunderstand those and end up reading then wrong.

# For other images
"""

placas= cv2.imread('/content/placa_rua.png') #your image here
result = reader.readtext(image = placas) #this time using default detail=1
result

"""The first output is based on a tuple with lists. Those lists are made of several arrays of numbers, a word, and a probability. The numbers are the segmentation of the image which could be letters, based on the model's training. The other outputs are the word it read and the probability that it is that word.

#Better explanation
"""

for (coordinates, text, probability) in result:
    if probability >= 0.7:
        (sup_left, sup_right, inferior_right, inferior_left) = coordinates
        sup_left = (int(sup_left[0]), int(sup_left[1]))
        sup_right = (int(sup_right[0]), int(sup_right[1]))
        inferior_right = (int(inferior_right[0]), int(inferior_right[1]))
        inferior_left = (int(inferior_left[0]), int(inferior_left[1]))
        cv2.rectangle(placas, sup_left, inferior_right, (0, 255, 0), 2)
        cv2.putText(placas, text, (sup_left[0] - 60, sup_left[1] + 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 150), 2)

plt.figure(figsize=(16, 16))
plt.axis('off')
plt.imshow(cv2.cvtColor(placas, cv2.COLOR_BGR2RGB))  # Convert BGR image to RGB for displaying
plt.show()

"""As you can see the images were almost correctly segmented and read. If you use lower probabilities, you will be able to receive the reading of the brown plank in the back of the image. But that plank has poor quality, so the probability is lower than 0.7. The better the image quality the better the segmentation and probability."""